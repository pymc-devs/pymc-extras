"""
T7) Model Equivalence

Given a saved LBFGS history (x_full, g_full, alpha_full, s_win_full, z_win_full)
and a fixed RNG seed, the ELBO computation must reproduce the reference values
recorded from the current streaming implementation.

Fixture files live in tests/pathfinder/fixtures/ and are generated by running:

    python tests/pathfinder/generate_fixtures.py

Each .npz file contains:
    x_full     – position history  (L, N)
    g_full     – gradient history  (L, N)
    alpha_full – diagonal scale    (L, N)
    s_win_full – s sliding window  (L, N, J)
    z_win_full – z sliding window  (L, N, J)
    elbo_ref   – reference ELBO    (L,)

Test strategy
-------------
Primary check (same code, same seed):
    Recompute ELBO on the saved state with ELBO_SEED; results must be
    bit-for-bit identical to elbo_ref.

Post-refactor fallback (seeds diverge due to changed RNG streams):
    If the values differ, we verify statistical equivalence:
    - Spearman rank correlation > 0.5
    - argmax within max(5, L//10) steps of the reference argmax
"""

import os

import numpy as np
import pymc as pm
import pytest

from pytensor.compile.mode import Mode

from pymc_extras.inference.pathfinder.pathfinder import (
    DEFAULT_LINKER,
    make_elbo_from_state_fn,
)
from tests.pathfinder.equivalence_models import MODEL_FACTORIES

# Must stay in sync with generate_fixtures.py
FIXTURES_DIR = os.path.join(os.path.dirname(__file__), "fixtures")
ELBO_SEED = 12345
MAXCOR = 6
NUM_ELBO_DRAWS = 100


# ---------------------------------------------------------------------------
# Helpers
# ---------------------------------------------------------------------------


def _load_fixture(name: str):
    path = os.path.join(FIXTURES_DIR, f"{name}.npz")
    if not os.path.exists(path):
        pytest.skip(
            f"Fixture not found: {path}. Run tests/pathfinder/generate_fixtures.py to create it."
        )
    with np.load(path) as data:
        required = ("x_full", "g_full", "alpha_full", "s_win_full", "z_win_full", "elbo_ref")
        if not all(k in data for k in required):
            pytest.skip(
                f"Fixture {path} is outdated (missing per-step state). "
                "Re-run tests/pathfinder/generate_fixtures.py to regenerate."
            )
        return (
            data["x_full"],
            data["g_full"],
            data["alpha_full"],
            data["s_win_full"],
            data["z_win_full"],
            data["elbo_ref"],
        )


def _compute_elbo(
    model: pm.Model,
    x_full,
    g_full,
    alpha_full,
    s_win_full,
    z_win_full,
    seed: int = ELBO_SEED,
) -> np.ndarray:
    """Recompute per-step ELBO using the exact saved per-step state."""
    compile_kwargs = {"mode": Mode(linker=DEFAULT_LINKER)}
    N = x_full.shape[1]
    elbo_fn = make_elbo_from_state_fn(
        model, N, MAXCOR, jacobian=True, compile_kwargs=compile_kwargs
    )
    rng = np.random.default_rng(seed)

    # x_full/g_full have initial point at row 0; accepted steps start at row 1
    L = alpha_full.shape[0]
    elbo = np.full(L, np.nan)
    for step in range(L):
        try:
            u = rng.standard_normal((NUM_ELBO_DRAWS, N))
            _, logQ, logP = elbo_fn(
                x_full[step + 1],
                g_full[step + 1],
                alpha_full[step],
                s_win_full[step],
                z_win_full[step],
                u,
            )
            logP = np.asarray(logP)
            logQ = np.asarray(logQ)
            finite = np.isfinite(logP) & np.isfinite(logQ)
            if np.any(finite):
                elbo[step] = float(np.mean(logP[finite] - logQ[finite]))
        except Exception:
            pass
    return elbo


# ---------------------------------------------------------------------------
# Tests
# ---------------------------------------------------------------------------


@pytest.mark.parametrize("model_name", list(MODEL_FACTORIES.keys()))
def test_elbo_all_finite(model_name):
    """Reference ELBO values recorded from current code must all be finite."""
    *_, elbo_ref = _load_fixture(model_name)
    assert np.all(np.isfinite(elbo_ref)), (
        f"[{model_name}] reference ELBO contains non-finite values: "
        f"{elbo_ref[~np.isfinite(elbo_ref)]}"
    )


@pytest.mark.parametrize("model_name", list(MODEL_FACTORIES.keys()))
def test_elbo_reproducible(model_name):
    """Recomputing ELBO on the saved state with the same seed must match reference exactly."""
    x_full, g_full, alpha_full, s_win_full, z_win_full, elbo_ref = _load_fixture(model_name)
    model = MODEL_FACTORIES[model_name]()
    elbo = _compute_elbo(model, x_full, g_full, alpha_full, s_win_full, z_win_full)

    assert (
        elbo.shape == elbo_ref.shape
    ), f"[{model_name}] shape mismatch: {elbo.shape} vs {elbo_ref.shape}"
    assert np.all(np.isfinite(elbo)), f"[{model_name}] recomputed ELBO contains non-finite values"
    np.testing.assert_array_equal(
        elbo,
        elbo_ref,
        err_msg=f"[{model_name}] ELBO values differ from reference (seed-aligned run should be identical)",
    )


def _check_statistical_equivalence(model_name, elbo, elbo_ref):
    """Shared helper: assert that elbo is statistically consistent with elbo_ref."""
    from scipy.stats import spearmanr

    L = len(elbo_ref)
    if L < 2:
        pytest.skip(f"[{model_name}] only {L} ELBO step(s), statistical check not meaningful")

    assert np.all(np.isfinite(elbo)), f"[{model_name}] ELBO contains non-finite values"

    corr, _ = spearmanr(elbo, elbo_ref)
    assert corr > 0.5, (
        f"[{model_name}] Spearman rank correlation {corr:.3f} < 0.5; "
        "ELBO ordering is inconsistent with reference"
    )

    argmax_new = int(np.argmax(elbo))
    argmax_ref = int(np.nanargmax(elbo_ref))
    tol = max(5, L // 5)
    assert abs(argmax_new - argmax_ref) <= tol, (
        f"[{model_name}] argmax {argmax_new} is more than {tol} steps from "
        f"reference argmax {argmax_ref} (L={L})"
    )


@pytest.mark.parametrize("model_name", list(MODEL_FACTORIES.keys()))
def test_elbo_statistical_equivalence(model_name):
    """
    Post-refactor guard: if the exact values diverge (e.g. due to changed RNG
    streams), statistical equivalence is required.
    """
    x_full, g_full, alpha_full, s_win_full, z_win_full, elbo_ref = _load_fixture(model_name)
    model = MODEL_FACTORIES[model_name]()
    elbo = _compute_elbo(model, x_full, g_full, alpha_full, s_win_full, z_win_full)
    _check_statistical_equivalence(model_name, elbo, elbo_ref)


@pytest.mark.parametrize("model_name", list(MODEL_FACTORIES.keys()))
def test_elbo_statistical_equivalence_different_seed(model_name):
    """
    Verify the statistical-equivalence tolerances are meaningful by using a
    seed that is deliberately different from the one used to generate the
    fixtures.
    """
    x_full, g_full, alpha_full, s_win_full, z_win_full, elbo_ref = _load_fixture(model_name)
    model = MODEL_FACTORIES[model_name]()
    elbo = _compute_elbo(
        model, x_full, g_full, alpha_full, s_win_full, z_win_full, seed=ELBO_SEED + 9999
    )
    _check_statistical_equivalence(model_name, elbo, elbo_ref)
